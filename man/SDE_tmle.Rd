% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SDE.R
\name{SDE_tmle}
\alias{SDE_tmle}
\title{SDE_tmle}
\usage{
SDE_tmle(data, a, a_star, sl, V = 10, covariates, truth = FALSE,
  truncate = list(lower = 0.01, upper = 0.99))
}
\arguments{
\item{data, }{data.frame of variables in time ordering from left to right}

\item{a, }{the treatment intervention of interest}

\item{a_star, }{the treatment intervention of the stochastic model for Mediator, M}

\item{sl}{the sl3 superlearner defined, see sl3 documentation for defining a superlearner
and the example below}

\item{V}{number of folds for cross-validation (fixed to 10 for now)}

\item{covariates, }{list of covariates for each necessary model, going backwards from the
outcome, Y, M, Z, A, W, S where S is the binary site, W are confounders, A is the treatment
Z is the intermediary confounder (binary) and M is the mediator, Y is the outcome.}

\item{truth}{for testing purposes input a list with names f_W, f_S, f_Z and f_Y models representing
and the corresponding elements are functions of appropriate variables so as to be able to
generate the truth and check the estimator's performance.  Default is NULL}

\item{truncate, }{a list with elements lower and upper to truncate the various p-scores
not functional at present}
}
\value{
a list with a CI for the estimate, and estimate using linear main terms MLE
gcomp formula (est_mle), the influence curve (IC), the superlearner coefficients for
the Y model and the QZ model (SL_coef)
}
\description{
computes the sequential regression, targeted maximum likelihood estimate
for the stochastic direct effect or stochastic indirect effect when the outcome and
mediator model are only available on site 1 (S = 1).  This is a data adaptive parameter
as the stochastic direct effect has a model for the mediator is determined on the data for
site 1.
}
\examples{
devtools::install_github("jeremyrcoyle/sl3")
devtools::install_github("jlstiles/SDE_transport")
library("SDEtransport")
library(sl3)

# data generating process for 1-d W
f_W = function(n) rnorm(n)
f_S = function(W) plogis(W +.7)
# make a pscore model
f_A = function(S,W) plogis(-.6*S-.7*W +.17)
# make a intermediate confounder model
f_Z = function(A,S,W) plogis(.1*S-.4*W+1*A-.3)
# make an M model according to the restrictions
f_M = function(Z,W,S) plogis(-.14*S + 1*W + 1.2*Z +.1)
# make a Y model according to the restrictions
f_Y = function(M,Z,W) {
  # plogis(1*M + 1.5*W*Z + 1*Z - W - .7*M*W - 1)
  # plogis(1*M  + Z - .68*W - 1)
  # plogis(1*M  - Z*M - .68*W^2*Z - .3*Z - (W > .7)*M*Z + (W < -.4)*M - 1)
  plogis(1*M -.5*cos(W) +.68*cos(W)*Z - .38*Z*M + (W < -.4)*M - 1)
}


# generate n random samples
n = 1e2
# set.seed(1)
data = gendata.SDEtransport(n, f_W = f_W, f_S = f_S, f_A = f_A, f_Z = f_Z, f_M = f_M, f_Y = f_Y)
mean(data$S==0)
# define learners in sl3
lglm = make_learner(Lrnr_glm)
lmean = make_learner(Lrnr_mean)
lxgboost = make_learner(Lrnr_xgboost, nrounds = 100, eta = .01, depth = 2)
lxgboost1 = make_learner(Lrnr_xgboost, nrounds = 20, eta = .4, depth = 2)
lrnr_stack = make_learner(Stack, list(lglm, lmean))
lrnr_stack = make_learner(Stack, list(lglm, lmean, lxgboost1))
metalearner = make_learner(Lrnr_nnls)

# define the superlearner
sl <- Lrnr_sl$new(learners = lrnr_stack,
                  metalearner = metalearner)

# declare covariates for the learners
covariates=list(covariates_Mstar = c("W", "Z"),
                covariates_Y = c("M", "Z", "W"),
                covariates_M = c("S", "W", "Z"),
                covariates_Z = c("W", "A", "S"),
                covariates_A = c("S","W"),
                covariates_S = c("W"))



# run the tmle
# a is the intervention, a_star is for the stochastic intervention.  For now, the stochastic
# intervention is defined on S = 1 only for both M and Z but can add options easily for that.
# There is a truth option for testing purposes to compute the true data adaptive parameter

a = 0
a_star = 1
res = SDE_tmle(data = data, a = a, a_star = a_star, sl = sl, covariates = covariates,
               truth = list(f_S = f_S, f_Z = f_Z, f_Y = f_Y),
               truncate = list(lower =.9, upper = .99))

# tmle est
res$CI
# mle gcomp
res$est_mle
# IC mean for tmle
mean(res$IC)
hist(res$IC, breaks = 50)
# sl coefficients for the learners
res$SL_coef
# true parameter value
res$Psi_0

}
